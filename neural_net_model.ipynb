{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "Age                     0\n",
       "Gender                  0\n",
       "Annual Income           0\n",
       "Marital Status          0\n",
       "Number of Dependents    0\n",
       "Education Level         0\n",
       "Occupation              0\n",
       "Health Score            0\n",
       "Location                0\n",
       "Policy Type             0\n",
       "Previous Claims         0\n",
       "Vehicle Age             0\n",
       "Credit Score            0\n",
       "Insurance Duration      0\n",
       "Policy Start Date       0\n",
       "Customer Feedback       0\n",
       "Smoking Status          0\n",
       "Exercise Frequency      0\n",
       "Property Type           0\n",
       "Premium Amount          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "objs = ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Policy Start Date', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n",
    "df_train[objs] = df_train[objs].apply(label_encoder.fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(['id', 'Premium Amount'], axis=1)\n",
    "y = df_train[['Premium Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.to_numpy()).float()\n",
    "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_train = torch.from_numpy(y_train.to_numpy()).float()\n",
    "y_test = torch.from_numpy(y_test.to_numpy()).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "model = SimpleNN(input_size).to(device)\n",
    "criterion = nn.SmoothL1Loss()  # For regression\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/1000], Loss: 641.3911\n",
      "Epoch [100/1000], Loss: 636.8344\n",
      "Epoch [150/1000], Loss: 632.3499\n",
      "Epoch [200/1000], Loss: 631.5598\n",
      "Epoch [250/1000], Loss: 631.9533\n",
      "Epoch [300/1000], Loss: 627.0450\n",
      "Epoch [350/1000], Loss: 630.9145\n",
      "Epoch [400/1000], Loss: 628.1098\n",
      "Epoch [450/1000], Loss: 627.4093\n",
      "Epoch [500/1000], Loss: 633.1374\n",
      "Epoch [550/1000], Loss: 631.7408\n",
      "Epoch [600/1000], Loss: 631.1218\n",
      "Epoch [650/1000], Loss: 625.0931\n",
      "Epoch [700/1000], Loss: 628.6318\n",
      "Epoch [750/1000], Loss: 622.1443\n",
      "Epoch [800/1000], Loss: 631.8849\n",
      "Epoch [850/1000], Loss: 615.1452\n",
      "Epoch [900/1000], Loss: 618.3213\n",
      "Epoch [950/1000], Loss: 624.0907\n",
      "Epoch [1000/1000], Loss: 619.5024\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 50 epochs\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "objs = ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Policy Start Date', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n",
    "df_test[objs] = df_test[objs].apply(label_encoder.fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calRMSLE(y_test, y_pred):\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    y_test = np.log1p(y_test)\n",
    "    y_pred = np.clip(y_pred, 0, None)\n",
    "    y_pred = np.log1p(y_pred)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmsle = np.sqrt(mse)\n",
    "\n",
    "    return rmsle\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Assume X_test is the data you want to make predictions on\n",
    "# Move X_test to the same device as the model\n",
    "X_test = X_test.to(device)\n",
    "\n",
    "# Use torch.no_grad() to turn off gradients\n",
    "with torch.no_grad():\n",
    "    # Pass the test data through the model\n",
    "    predictions = model(X_test)\n",
    "\n",
    "# Convert predictions if necessary, e.g., from tensors to NumPy arrays\n",
    "predictions = predictions.cpu().numpy()  # Move to CPU before converting to NumPy\n",
    "\n",
    "# If your model is for regression, predictions will be continuous values.\n",
    "# For classification, you may need to apply a threshold or use the softmax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0880315"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calRMSLE(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "Age                     0\n",
       "Gender                  0\n",
       "Annual Income           0\n",
       "Marital Status          0\n",
       "Number of Dependents    0\n",
       "Education Level         0\n",
       "Occupation              0\n",
       "Health Score            0\n",
       "Location                0\n",
       "Policy Type             0\n",
       "Previous Claims         0\n",
       "Vehicle Age             0\n",
       "Credit Score            0\n",
       "Insurance Duration      0\n",
       "Policy Start Date       0\n",
       "Customer Feedback       0\n",
       "Smoking Status          0\n",
       "Exercise Frequency      0\n",
       "Property Type           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "objs = ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', 'Policy Start Date', 'Customer Feedback', 'Smoking Status', 'Exercise Frequency', 'Property Type']\n",
    "df_test[objs] = df_test[objs].apply(label_encoder.fit_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the logic to fill missing values\n",
    "proc_df = df_test.apply(\n",
    "    lambda col: col.fillna(col.mean()) if col.dtypes in ['int64', 'float64'] \n",
    "    else col.fillna(col.mode().iloc[0]) if col.dtypes == 'object' or col.nunique() < 10\n",
    "    else col,\n",
    "    axis=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.apply(lambda col: col.fillna(col.mean()) if col.dtype != 'object' else col, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Assume X_test is the data you want to make predictions on\n",
    "# Move X_test to the same device as the model\n",
    "\n",
    "\n",
    "df1 = torch.from_numpy(df1.to_numpy()).float()\n",
    "df1 = df1.to(device)\n",
    "\n",
    "# Use torch.no_grad() to turn off gradients\n",
    "with torch.no_grad():\n",
    "    # Pass the test data through the model\n",
    "    predictions = model(df1)\n",
    "\n",
    "\n",
    "predictions = predictions.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame({\n",
    "    'id' : df_test['id'].tolist(),\n",
    "    'Premium Amount': predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "Premium Amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
